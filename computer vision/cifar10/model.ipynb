{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# img, label = train_dataset[0], train_dataset[1]\n",
    "img, label = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\matplotlib\\text.py:1215: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img[1])\n",
    "plt.title(label[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (10000, 32, 32, 3) (40000, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.length = len(X)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        # y = torch.zeros(10)\n",
    "        # y[self.y[idx][0]] = 1\n",
    "        y = self.y[idx].squeeze()\n",
    "        X_tensor = torch.from_numpy(X).to(torch.float32).permute(2, 0, 1)\n",
    "        y_tensor = torch.tensor(y).to(torch.long)\n",
    "        return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(X_train, y_train)\n",
    "val_data = MyDataset(X_val, y_val)\n",
    "test_data = MyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 70.,  75.,  80.,  ...,  86.,  82.,  78.],\n",
       "           [ 74.,  79.,  83.,  ...,  91.,  88.,  85.],\n",
       "           [ 85.,  87.,  89.,  ..., 101.,  98.,  94.],\n",
       "           ...,\n",
       "           [118., 133., 139.,  ..., 117., 114.,  99.],\n",
       "           [121., 135., 136.,  ..., 107., 111., 109.],\n",
       "           [130., 132., 145.,  ..., 111., 108., 107.]],\n",
       " \n",
       "          [[120., 124., 127.,  ..., 132., 130., 126.],\n",
       "           [124., 128., 131.,  ..., 138., 134., 131.],\n",
       "           [132., 133., 136.,  ..., 147., 142., 137.],\n",
       "           ...,\n",
       "           [102., 115., 119.,  ..., 101.,  97.,  84.],\n",
       "           [106., 116., 113.,  ...,  93.,  97.,  96.],\n",
       "           [114., 112., 123.,  ...,  99.,  95.,  93.]],\n",
       " \n",
       "          [[205., 210., 215.,  ..., 219., 216., 212.],\n",
       "           [208., 214., 219.,  ..., 224., 220., 217.],\n",
       "           [216., 220., 224.,  ..., 231., 226., 222.],\n",
       "           ...,\n",
       "           [ 66.,  80.,  88.,  ...,  71.,  68.,  56.],\n",
       "           [ 72.,  83.,  83.,  ...,  63.,  69.,  69.],\n",
       "           [ 83.,  79.,  90.,  ...,  66.,  68.,  67.]]],\n",
       " \n",
       " \n",
       "         [[[120., 121., 116.,  ..., 127., 130., 133.],\n",
       "           [130., 129., 129.,  ..., 118., 119., 115.],\n",
       "           [132., 127., 125.,  ..., 124., 121., 117.],\n",
       "           ...,\n",
       "           [134., 131., 153.,  ..., 157., 164., 174.],\n",
       "           [153., 150., 169.,  ..., 170., 179., 189.],\n",
       "           [175., 173., 179.,  ..., 185., 188., 194.]],\n",
       " \n",
       "          [[133., 132., 127.,  ..., 140., 143., 144.],\n",
       "           [145., 141., 142.,  ..., 136., 136., 131.],\n",
       "           [146., 138., 139.,  ..., 139., 135., 131.],\n",
       "           ...,\n",
       "           [149., 146., 166.,  ..., 157., 164., 174.],\n",
       "           [166., 161., 178.,  ..., 169., 179., 190.],\n",
       "           [183., 182., 187.,  ..., 184., 189., 196.]],\n",
       " \n",
       "          [[149., 148., 143.,  ..., 157., 158., 159.],\n",
       "           [172., 166., 166.,  ..., 165., 163., 156.],\n",
       "           [163., 156., 156.,  ..., 163., 157., 152.],\n",
       "           ...,\n",
       "           [169., 161., 179.,  ..., 153., 161., 171.],\n",
       "           [180., 172., 188.,  ..., 165., 177., 188.],\n",
       "           [185., 190., 193.,  ..., 182., 187., 198.]]],\n",
       " \n",
       " \n",
       "         [[[145., 133., 117.,  ..., 134., 150., 157.],\n",
       "           [149., 139., 118.,  ..., 143., 159., 155.],\n",
       "           [148., 135., 122.,  ..., 148., 158., 149.],\n",
       "           ...,\n",
       "           [ 99.,  90.,  81.,  ...,  78.,  99., 104.],\n",
       "           [111.,  94., 101.,  ..., 119.,  95., 104.],\n",
       "           [120., 125., 127.,  ..., 109.,  69.,  78.]],\n",
       " \n",
       "          [[158., 149., 136.,  ..., 146., 159., 163.],\n",
       "           [160., 153., 134.,  ..., 156., 171., 166.],\n",
       "           [156., 146., 135.,  ..., 161., 173., 165.],\n",
       "           ...,\n",
       "           [113.,  98.,  84.,  ...,  86., 107., 113.],\n",
       "           [123., 101., 104.,  ..., 130., 105., 115.],\n",
       "           [127., 133., 138.,  ..., 119.,  76.,  86.]],\n",
       " \n",
       "          [[ 95.,  86.,  71.,  ..., 103., 117., 121.],\n",
       "           [103.,  93.,  72.,  ..., 109., 124., 119.],\n",
       "           [102.,  92.,  81.,  ..., 109., 120., 112.],\n",
       "           ...,\n",
       "           [ 57.,  59.,  61.,  ...,  38.,  58.,  62.],\n",
       "           [ 70.,  73.,  91.,  ...,  59.,  40.,  43.],\n",
       "           [ 93., 100.,  96.,  ...,  55.,  31.,  38.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 17.,  14.,  12.,  ...,  13.,  14.,  15.],\n",
       "           [ 17.,  15.,  14.,  ...,  15.,  15.,  16.],\n",
       "           [ 15.,  15.,  14.,  ...,  19.,  18.,  18.],\n",
       "           ...,\n",
       "           [ 34.,  63., 138.,  ..., 140., 137., 136.],\n",
       "           [ 28.,  57., 129.,  ..., 136., 133., 130.],\n",
       "           [ 31.,  49., 118.,  ..., 125., 123., 121.]],\n",
       " \n",
       "          [[ 13.,  12.,  11.,  ...,  13.,  15.,  17.],\n",
       "           [ 14.,  13.,  11.,  ...,  13.,  15.,  17.],\n",
       "           [ 13.,  12.,  11.,  ...,  18.,  17.,  17.],\n",
       "           ...,\n",
       "           [ 39.,  66., 149.,  ..., 156., 154., 154.],\n",
       "           [ 31.,  59., 140.,  ..., 151., 150., 147.],\n",
       "           [ 33.,  50., 126.,  ..., 139., 139., 138.]],\n",
       " \n",
       "          [[ 19.,  17.,  16.,  ...,  18.,  20.,  25.],\n",
       "           [ 19.,  18.,  17.,  ...,  19.,  20.,  25.],\n",
       "           [ 19.,  18.,  17.,  ...,  22.,  22.,  24.],\n",
       "           ...,\n",
       "           [ 42.,  64., 136.,  ..., 143., 142., 143.],\n",
       "           [ 34.,  58., 128.,  ..., 139., 139., 137.],\n",
       "           [ 34.,  50., 116.,  ..., 128., 130., 128.]]],\n",
       " \n",
       " \n",
       "         [[[178., 182., 183.,  ..., 184., 186., 187.],\n",
       "           [181., 186., 187.,  ..., 185., 186., 187.],\n",
       "           [178., 183., 187.,  ..., 181., 182., 181.],\n",
       "           ...,\n",
       "           [192., 195., 204.,  ..., 200., 200., 202.],\n",
       "           [194., 195., 201.,  ..., 203., 203., 204.],\n",
       "           [193., 194., 195.,  ..., 200., 199., 199.]],\n",
       " \n",
       "          [[ 26.,  28.,  27.,  ...,  26.,  27.,  32.],\n",
       "           [ 26.,  27.,  27.,  ...,  24.,  24.,  26.],\n",
       "           [ 24.,  24.,  26.,  ...,  23.,  23.,  24.],\n",
       "           ...,\n",
       "           [ 26.,  29.,  32.,  ...,  35.,  35.,  36.],\n",
       "           [ 28.,  29.,  29.,  ...,  35.,  35.,  36.],\n",
       "           [ 28.,  28.,  28.,  ...,  33.,  32.,  33.]],\n",
       " \n",
       "          [[ 45.,  46.,  44.,  ...,  43.,  46.,  54.],\n",
       "           [ 45.,  46.,  44.,  ...,  41.,  43.,  47.],\n",
       "           [ 42.,  42.,  43.,  ...,  39.,  42.,  44.],\n",
       "           ...,\n",
       "           [ 43.,  46.,  52.,  ...,  54.,  54.,  58.],\n",
       "           [ 45.,  46.,  49.,  ...,  55.,  55.,  59.],\n",
       "           [ 46.,  46.,  47.,  ...,  53.,  52.,  56.]]],\n",
       " \n",
       " \n",
       "         [[[193., 184., 187.,  ..., 176., 174., 181.],\n",
       "           [185., 174., 178.,  ..., 161., 159., 166.],\n",
       "           [178., 162., 164.,  ..., 183., 179., 180.],\n",
       "           ...,\n",
       "           [152., 103., 112.,  ..., 122., 115., 142.],\n",
       "           [157., 109., 116.,  ..., 120., 113., 142.],\n",
       "           [184., 168., 176.,  ..., 172., 170., 179.]],\n",
       " \n",
       "          [[190., 182., 188.,  ..., 186., 183., 187.],\n",
       "           [183., 173., 179.,  ..., 185., 182., 184.],\n",
       "           [178., 163., 167.,  ..., 203., 201., 195.],\n",
       "           ...,\n",
       "           [151.,  97., 104.,  ..., 111., 105., 136.],\n",
       "           [158., 104., 110.,  ..., 114., 106., 140.],\n",
       "           [184., 162., 168.,  ..., 168., 166., 178.]],\n",
       " \n",
       "          [[191., 183., 186.,  ..., 201., 199., 195.],\n",
       "           [184., 174., 179.,  ..., 203., 201., 196.],\n",
       "           [177., 164., 170.,  ..., 210., 211., 201.],\n",
       "           ...,\n",
       "           [132.,  56.,  48.,  ...,  52.,  48.,  98.],\n",
       "           [143.,  73.,  68.,  ...,  74.,  65., 110.],\n",
       "           [183., 151., 151.,  ..., 157., 150., 167.]]]]),\n",
       " tensor([0, 5, 4, 4, 9, 9, 2, 9, 2, 0, 6, 5, 3, 3, 5, 2, 4, 8, 3, 2, 4, 8, 1, 8,\n",
       "         8, 2, 8, 2, 5, 1, 3, 7])]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, output_size, shape):\n",
    "        super(Cifar, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_size, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*shape*shape, out_features=output_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cifar(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=250, out_features=10, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cifar(input_size=3, hidden_units=10, output_size=10, shape=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "    model.train()\n",
    "    train_loss, accuracy = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        accuracy += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "    accuracy = accuracy/len(dataloader)\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        device=\"cpu\"\n",
    "    ):\n",
    "    model.eval()\n",
    "    test_loss, accuracy = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            accuracy += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "    accuracy = accuracy/len(dataloader)\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n",
      "torch.Size([32, 10, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\2370505637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                        \u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                        \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                                        optimizer=optimizer)\n\u001b[0m\u001b[0;32m     14\u001b[0m     test_loss, test_acc = test(model=model,\n\u001b[0;32m     15\u001b[0m                                     \u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\3553953543.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_fn, optimizer, dataloader, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6828\\1133961108.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\18raj\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 460\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_accuracy\": []\n",
    "}\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model=model,\n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer)\n",
    "    test_loss, test_acc = test(model=model,\n",
    "                                    dataloader=val_dataloader,\n",
    "                                    loss_fn=loss_fn)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_accuracy\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_accuracy\"].append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
